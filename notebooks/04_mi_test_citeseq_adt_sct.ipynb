{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "import muon as mu\n",
    "import mudata as md \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to do an assessment of mutual information between the CITE-seq ADT (surface protein expression) and cytoplasmic RNA expression (SCT) in the PBMC cells. \n",
    "\n",
    "The MI will be estimated using LMI (https://arxiv.org/abs/2409.02732). First install the LMI library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: latentmi in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (0.1.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from latentmi) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.5.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from latentmi) (1.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.13.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from latentmi) (1.13.1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.3.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from latentmi) (2.3.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from latentmi) (4.66.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.5.0->latentmi) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.5.0->latentmi) (3.5.0)\n",
      "Requirement already satisfied: filelock in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (4.12.2)\n",
      "Requirement already satisfied: sympy in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (1.13.0)\n",
      "Requirement already satisfied: networkx in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from torch<3.0.0,>=2.3.0->latentmi) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from jinja2->torch<3.0.0,>=2.3.0->latentmi) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /fs01/home/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages (from sympy->torch<3.0.0,>=2.3.0->latentmi) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install latentmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/mudata/_core/mudata.py:489: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Load the MuData object (This is a big file - should have at last 16GB of RAM to prevent memory issues)\n",
    "mdata = md.read(\"../data/multi.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and subset the counts for SCT and ADT. We'll sample 1000 cells to start with to speed up the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.random.choice(mdata[\"SCT\"].shape[0], 1000, replace=False)\n",
    "#sct_counts = mdata[\"SCT\"].X[indices, :].todense()\n",
    "#adt_counts = mdata[\"ADT\"].X[indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the latentmi function in this respect \n",
    "# from latentmi import lmi\n",
    "\n",
    "#pmis, embedding, model = lmi.estimate(sct_counts, adt_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000 cells take too long of a time- test with 1000 instead - this is also taking a long time. \n",
    "\n",
    "Try with 2500 HVGs instead and 1000 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n",
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  Ys = torch.from_numpy(np.nan_to_num((Ys - Ys.mean(axis=0)) / Ys.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 297 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n",
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  Ys = torch.from_numpy(np.nan_to_num((Ys - Ys.mean(axis=0)) / Ys.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 299 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:193: RuntimeWarning: invalid value encountered in divide\n",
      "  Xs = torch.from_numpy(np.nan_to_num((Xs - Xs.mean(axis=0)) / Xs.std(axis=0))).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 296 (of max 300) ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»ðŸŒ»"
     ]
    }
   ],
   "source": [
    "# Get HVG subset of SCT\n",
    "sc.pp.highly_variable_genes(mdata[\"SCT\"], n_top_genes=2000)\n",
    "sct_counts = mdata[\"SCT\"].X[:, mdata[\"SCT\"].var.highly_variable]\n",
    "adt_counts = mdata[\"ADT\"].X\n",
    "\n",
    "# Randomly sample 1000 cells with a seed - repeat 10 times \n",
    "from latentmi import lmi\n",
    "\n",
    "n_mi_calc = 10\n",
    "MI_real = np.zeros(n_mi_calc)\n",
    "for i in range(n_mi_calc):\n",
    "    np.random.seed(i)\n",
    "    indices = np.random.choice(mdata[\"SCT\"].shape[0], 1000, replace=True)\n",
    "    sct_counts_sub = sct_counts[indices, :].todense()\n",
    "    adt_counts_sub = adt_counts[indices, :]\n",
    "    pmis, _, _ = lmi.estimate(sct_counts_sub, adt_counts_sub)\n",
    "    MI_real[i] = np.nanmean(pmis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m sct_sim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39msct_counts\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m adt_sim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(size\u001b[38;5;241m=\u001b[39madt_counts\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m pmis, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlmi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msct_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madt_sim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m MI_simulations[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(pmis)\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:210\u001b[0m, in \u001b[0;36mestimate\u001b[0;34m(Xs, Ys, regularizer, alpha, lam, N_dims, validation_split, estimate_on_val, batch_size, lr, epochs, patience, quiet, device)\u001b[0m\n\u001b[1;32m    206\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m indices[:N_train]\n\u001b[1;32m    207\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m indices[N_train:]\n\u001b[0;32m--> 210\u001b[0m Zx, Zy, model \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m            \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(Zx)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(Zy)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    217\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaNs in embedding! converted to 0s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:152\u001b[0m, in \u001b[0;36mlearn_representation\u001b[0;34m(Xs, Ys, train_indices, test_indices, regularizer, alpha, lam, N_dims, batch_size, lr, epochs, validation_split, patience, quiet, device)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# assert X_train.shape[1] // 4 > 0, \"Hidden layer with size 0. Consider tiling input.\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# assert Y_train.shape[1] // 4 > 0, \"Hidden layer with size 0. Consider tiling input.\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(regularizer)(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], N_dims, \n\u001b[1;32m    150\u001b[0m                           alpha\u001b[38;5;241m=\u001b[39malpha, lam\u001b[38;5;241m=\u001b[39mlam)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m      \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    157\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/latentmi/lmi.py:79\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, Y_train, X_test, Y_test, batch_size, lr, epochs, patience, quiet)\u001b[0m\n\u001b[1;32m     76\u001b[0m     model_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlearning_loss(X, Y)\n\u001b[1;32m     78\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mmodel_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# validation \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now simulate a bunch of random gaussian distributions with the same dimensions as the adt and sct counts and calculate the MI for each of them\n",
    "# This will give us a null distribution to compare the MI estimate to\n",
    "\n",
    "n_simulations = 20\n",
    "MI_simulations = np.zeros(n_simulations)\n",
    "for i in range(n_simulations):\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    np.random.seed(seed)\n",
    "    sct_sim = np.random.normal(size=sct_counts.shape)\n",
    "    adt_sim = np.random.normal(size=adt_counts.shape)\n",
    "    pmis, _, _ = lmi.estimate(sct_sim, adt_sim)\n",
    "    MI_simulations[i] = np.nanmean(pmis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MI estimate from the calculation and the MI estimates from the simulations\n",
    "np.save(\"../data/MI_estimate_10k_10_times_adt_sct.npy\", MI_real)\n",
    "np.save(\"../data/MI_simulations_100_gaussian.npy\", MI_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next see if MI changes based on the celltypes \n",
    "\n",
    "# Extract list of all celltypes from the mdata\n",
    "celltypes = mdata.obs[\"celltype\"].values\n",
    "\n",
    "sct_counts = mdata[\"SCT\"].X[:, mdata[\"SCT\"].var.highly_variable]\n",
    "adt_counts = mdata[\"ADT\"].X\n",
    "\n",
    "# Sample 500 cells from each celltype (that has at least 500 cells)\n",
    "celltype_counts_sct = []\n",
    "celltype_counts_adt = []\n",
    "celltype_names = []\n",
    "for celltype in np.unique(celltypes):\n",
    "    if np.sum(celltypes == celltype) >= 500:\n",
    "        celltype_names.append(celltype)\n",
    "        indices = np.random.choice(np.where(celltypes == celltype)[0], 500, replace=False)\n",
    "        celltype_counts_sct.append(sct_counts[indices, :])\n",
    "        celltype_counts_adt.append(adt_counts[indices, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MI for each celltype\n",
    "MI_celltypes = np.zeros(len(celltype_counts_sct))\n",
    "for i in range(len(celltype_counts_sct)):\n",
    "    pmis, _, _ = lmi.estimate(celltype_counts_sct[i], celltype_counts_adt[i])\n",
    "    MI_celltypes[i] = np.nanmean(pmis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MI estimates for each celltype\n",
    "np.save(\"../data/MI_celltypes_500.npy\", MI_celltypes)\n",
    "np.save(\"../data/celltype_names.npy\", celltype_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22703302, 1.3373473 , 1.33634926, 1.49309576, 1.29223626,\n",
       "       1.1476103 , 1.12761659, 1.58551109, 1.23129204, 1.33487984])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeseq_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
