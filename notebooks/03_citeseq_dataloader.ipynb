{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "from mudata import MuData\n",
    "import muon as mu\n",
    "import mudata as md \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/mudata/_core/mudata.py:489: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Load the MuData object (This is a big file - should have at last 16GB of RAM to prevent memory issues)\n",
    "mdata = md.read(\"../data/multi.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CITEData class to store the data and the operations to be performed on the data. The class will have the following methods:\n",
    "\n",
    "- init\n",
    "- format\n",
    "- normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CITEData(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for storing the CITE-seq data, and creating dataloaders for training and testing the model.    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mudata, esm_embeddings = False, scgpt_embeddings = False,\n",
    "                 orthrus_embeddings = False, hvgs = False, hvg_values = None):\n",
    "        \n",
    "        self.mudata = mudata\n",
    "        \n",
    "        # For each of the embeddings, create arrays to store them by extracting them from the .obs \n",
    "        # columns of the MuData objects\n",
    "        if esm_embeddings:\n",
    "            # Grep all cols in the adt var that start with \"esm_\"\n",
    "            esm_cols = [col for col in self.mudata[\"ADT\"].var.columns if col.startswith(\"esm_\")]\n",
    "            self.esm_embeddings = np.zeros(((self.mudata[\"ADT\"].shape[1]), len(esm_cols)))\n",
    "            for col in esm_cols:\n",
    "                self.esm_embeddings[:, col] = self.mudata[\"ADT\"].var[col].values\n",
    "                \n",
    "        else:\n",
    "            esm_embeddings = None\n",
    "                \n",
    "        if orthrus_embeddings:\n",
    "            # Grep all cols in the adt var that start with \"orthrus_\"\n",
    "            orthrus_cols = [col for col in self.mudata[\"ADT\"].var.columns if col.startswith(\"orthrus_\")]\n",
    "            self.orthrus_embeddings = np.zeros(((self.mudata[\"ADT\"].shape[1]), len(orthrus_cols)))\n",
    "            for col in orthrus_cols:\n",
    "                self.orthrus_embeddings[:, col] = self.mudata[\"ADT\"].var[col].values\n",
    "        else:\n",
    "            orthrus_embeddings = None\n",
    "                \n",
    "        if scgpt_embeddings:\n",
    "            # Grep all cols in the sct obs that start with \"scgpt_\"\n",
    "            scgpt_cols = [col for col in self.mudata[\"SCT\"].obs.columns if col.startswith(\"scgpt_\")] \n",
    "            self.scgpt_embeddings = np.zeros(((self.mudata[\"SCT\"].shape[0]), len(scgpt_cols)))\n",
    "            for col in scgpt_cols:\n",
    "                self.scgpt_embeddings[:, col] = self.mudata[\"SCT\"].obs[col].values\n",
    "        else:\n",
    "            scgpt_embeddings = None\n",
    "            \n",
    "        # Get the HVG indices if indicated\n",
    "        if hvgs:\n",
    "            self.hvg_indices = hvg_values\n",
    "        else:\n",
    "            self.hvg_indices = None\n",
    "            \n",
    "        # Extract the counts for ADT and SCT - SCT based on highly variable genes \n",
    "        self.adt_counts = self.mudata[\"ADT\"].X\n",
    "        if hvg_values is not None:\n",
    "            self.sct_counts = self.mudata[\"SCT\"][:, hvg_values == 1].X\n",
    "        else:\n",
    "            self.sct_counts = self.mudata[\"SCT\"].X\n",
    "            \n",
    "    def format(self, normalize_sct = False, normalize_adt = False, standardize = False):\n",
    "        \"\"\"\n",
    "        Normalize the data in the MuData object, and format it for training the model.\n",
    "        \"\"\"\n",
    "        # Save the raw data in .raw attributes for both adt and sct\n",
    "        self.mudata[\"ADT\"].raw = self.mudata[\"ADT\"].X.copy()\n",
    "        self.mudata[\"SCT\"].raw = self.mudata[\"SCT\"].X.copy()\n",
    "        \n",
    "        # Normalize the data if indicated \n",
    "        if normalize_sct:\n",
    "            sc.pp.normalize_total(self.mudata[\"SCT\"], target_sum=1e4)\n",
    "            sc.pp.log1p(self.mudata[\"SCT\"])\n",
    "            \n",
    "        if normalize_adt:\n",
    "            sc.pp.normalize_total(self.mudata[\"ADT\"], target_sum=1000)\n",
    "            sc.pp.log1p(self.mudata[\"ADT\"])\n",
    "        \n",
    "        # Standardize the data if indicated - ideally we don't do this \n",
    "        # to prevent data leakage. The normalize_total and log1p functions\n",
    "        # are invariant to test/train splits.\n",
    "        if standardize:\n",
    "            sc.pp.scale(self.mudata[\"SCT\"])\n",
    "            sc.pp.scale(self.mudata[\"ADT\"])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.mudata[\"ADT\"].shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the data for a given index\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        # This is assuming we're already adding everything - the conditional otherwise is long but can be done too\n",
    "        return self.sct_counts[idx], self.adt_counts[idx], self.esm_embeddings[idx], self.orthrus_embeddings[idx], self.scgpt_embeddings[idx]\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for only highly variable genes for SCT (highly variable is already in the .var attribute)\n",
    "highly_variable = mdata[\"SCT\"].var.highly_variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset mdata sct such that if highly_variable ==1, the vars are kept \n",
    "sct_subset = mdata[\"SCT\"][:, highly_variable == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 161764 × 5000\n",
       "    var: 'highly_variable'\n",
       "    uns: 'pca', 'spca'\n",
       "    obsm: 'X_pca', 'X_spca'\n",
       "    varm: 'PCs', 'spca'\n",
       "    layers: 'counts'\n",
       "    obsp: 'wknn', 'wsnn'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sct_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([184,  44]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if var names from ADT are in RNA - the lenght is not the same\n",
    "np.unique(np.isin(mdata[\"ADT\"].var_names, mdata[\"SCT\"].var_names), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AL627309.1    0\n",
       "AL669831.5    0\n",
       "LINC00115     0\n",
       "FAM41C        0\n",
       "NOC2L         0\n",
       "             ..\n",
       "AC016588.1    0\n",
       "FAM83E        0\n",
       "Z82244.2      0\n",
       "AP001468.1    0\n",
       "AP001469.2    0\n",
       "Name: highly_variable, Length: 20729, dtype: uint8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highly_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeseq_env",
   "language": "python",
   "name": "citeseq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
