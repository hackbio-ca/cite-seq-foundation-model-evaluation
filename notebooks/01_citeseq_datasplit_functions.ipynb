{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scanpy as sc \n",
    "import anndata as ann \n",
    "from mudata import MuData\n",
    "import mudata as md \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/mudata/_core/mudata.py:489: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Load the MuData object (This is a big file - should have at last 16GB of RAM to prevent memory issues)\n",
    "mdata = md.read(\"../data/multi.h5mu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function - Scenario 1. \n",
    "\n",
    "In this scenario, the MuonData object is split such that there is a 60% training set, 10% validation set, and 30% test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scenario_1_split(mudata_object, train_size = 0.6, val_size = 0.1, test_size = 0.3, seed = 42):\n",
    "    \"\"\"\n",
    "    Split the MuonData object into training, validation, and test sets. In this scenario, the split is \n",
    "    based on the rows (cells) of the MuonData object.\n",
    "    \n",
    "    Parameters:\n",
    "    mudata_object (MuonData): MuonData object to split\n",
    "    train_size (float): Proportion of the dataset to include in the training set\n",
    "    val_size (float): Proportion of the dataset to include in the validation set\n",
    "    test_size (float): Proportion of the dataset to include in the test set\n",
    "    \n",
    "    Returns:\n",
    "    train_data (MuonData): MuonData object with annotations for train, val, test splits\n",
    "    \"\"\"\n",
    "    # Get the indices of the mdata by enumerating over shape\n",
    "    mudata_indices = [i for i in range(mudata_object.shape[0])]\n",
    "    \n",
    "    # Set the seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Split the indices based on the specified test/train/validation sizes\n",
    "    train_indices, test_indices = train_test_split(mudata_indices, train_size=train_size)\n",
    "    val_indices, test_indices = train_test_split(test_indices, train_size=(val_size/(val_size + test_size)))\n",
    "    \n",
    "    # Add the indices to the obs of the ADT and SCT aspects of the MuonData object\n",
    "    mudata_object[\"ADT\"].obs[\"Split\"] = \"None\"\n",
    "    mudata_object[\"ADT\"].obs[\"Split\"][train_indices] = \"Train\"\n",
    "    mudata_object[\"ADT\"].obs[\"Split\"][val_indices] = \"Validation\"\n",
    "    mudata_object[\"ADT\"].obs[\"Split\"][test_indices] = \"Test\"\n",
    "    \n",
    "    mudata_object[\"SCT\"].obs[\"Split\"] = \"None\"\n",
    "    mudata_object[\"SCT\"].obs[\"Split\"][train_indices] = \"Train\"\n",
    "    mudata_object[\"SCT\"].obs[\"Split\"][val_indices] = \"Validation\"\n",
    "    mudata_object[\"SCT\"].obs[\"Split\"][test_indices] = \"Test\"\n",
    "    \n",
    "    # Return the annotated \n",
    "    return mudata_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = scenario_1_split(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>View of MuData object with n_obs × n_vars = 150 × 20957\n",
       "  obs:\t&#x27;nCount_ADT&#x27;, &#x27;nFeature_ADT&#x27;, &#x27;nCount_RNA&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;orig.ident&#x27;, &#x27;lane&#x27;, &#x27;donor&#x27;, &#x27;time&#x27;, &#x27;celltype.l1&#x27;, &#x27;celltype.l2&#x27;, &#x27;celltype.l3&#x27;, &#x27;Phase&#x27;, &#x27;nCount_SCT&#x27;, &#x27;nFeature_SCT&#x27;\n",
       "  obsm:\t&#x27;X_aumap&#x27;, &#x27;X_umap&#x27;, &#x27;X_wnn.umap&#x27;\n",
       "  2 modalities\n",
       "    SCT:\t150 x 20729\n",
       "      var:\t&#x27;highly_variable&#x27;\n",
       "      uns:\t&#x27;pca&#x27;, &#x27;spca&#x27;\n",
       "      obsm:\t&#x27;X_pca&#x27;, &#x27;X_spca&#x27;\n",
       "      varm:\t&#x27;PCs&#x27;, &#x27;spca&#x27;\n",
       "      layers:\t&#x27;counts&#x27;\n",
       "      obsp:\t&#x27;wknn&#x27;, &#x27;wsnn&#x27;\n",
       "    ADT:\t150 x 228\n",
       "      var:\t&#x27;highly_variable&#x27;, &#x27;Split&#x27;\n",
       "      uns:\t&#x27;apca&#x27;\n",
       "      obsm:\t&#x27;X_apca&#x27;\n",
       "      varm:\t&#x27;apca&#x27;\n",
       "      layers:\t&#x27;counts&#x27;</pre>"
      ],
      "text/plain": [
       "View of MuData object with n_obs × n_vars = 150 × 20957\n",
       "  obs:\t'nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2', 'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'\n",
       "  obsm:\t'X_aumap', 'X_umap', 'X_wnn.umap'\n",
       "  2 modalities\n",
       "    SCT:\t150 x 20729\n",
       "      var:\t'highly_variable'\n",
       "      uns:\t'pca', 'spca'\n",
       "      obsm:\t'X_pca', 'X_spca'\n",
       "      varm:\t'PCs', 'spca'\n",
       "      layers:\t'counts'\n",
       "      obsp:\t'wknn', 'wsnn'\n",
       "    ADT:\t150 x 228\n",
       "      var:\t'highly_variable', 'Split'\n",
       "      uns:\t'apca'\n",
       "      obsm:\t'X_apca'\n",
       "      varm:\t'apca'\n",
       "      layers:\t'counts'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>View of MuData object with n_obs × n_vars = 75 × 20957\n",
       "  obs:\t&#x27;nCount_ADT&#x27;, &#x27;nFeature_ADT&#x27;, &#x27;nCount_RNA&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;orig.ident&#x27;, &#x27;lane&#x27;, &#x27;donor&#x27;, &#x27;time&#x27;, &#x27;celltype.l1&#x27;, &#x27;celltype.l2&#x27;, &#x27;celltype.l3&#x27;, &#x27;Phase&#x27;, &#x27;nCount_SCT&#x27;, &#x27;nFeature_SCT&#x27;\n",
       "  obsm:\t&#x27;X_aumap&#x27;, &#x27;X_umap&#x27;, &#x27;X_wnn.umap&#x27;\n",
       "  2 modalities\n",
       "    SCT:\t75 x 20729\n",
       "      var:\t&#x27;highly_variable&#x27;\n",
       "      uns:\t&#x27;pca&#x27;, &#x27;spca&#x27;\n",
       "      obsm:\t&#x27;X_pca&#x27;, &#x27;X_spca&#x27;\n",
       "      varm:\t&#x27;PCs&#x27;, &#x27;spca&#x27;\n",
       "      layers:\t&#x27;counts&#x27;\n",
       "      obsp:\t&#x27;wknn&#x27;, &#x27;wsnn&#x27;\n",
       "    ADT:\t75 x 228\n",
       "      var:\t&#x27;highly_variable&#x27;, &#x27;Split&#x27;\n",
       "      uns:\t&#x27;apca&#x27;\n",
       "      obsm:\t&#x27;X_apca&#x27;\n",
       "      varm:\t&#x27;apca&#x27;\n",
       "      layers:\t&#x27;counts&#x27;</pre>"
      ],
      "text/plain": [
       "View of MuData object with n_obs × n_vars = 75 × 20957\n",
       "  obs:\t'nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA', 'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2', 'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'\n",
       "  obsm:\t'X_aumap', 'X_umap', 'X_wnn.umap'\n",
       "  2 modalities\n",
       "    SCT:\t75 x 20729\n",
       "      var:\t'highly_variable'\n",
       "      uns:\t'pca', 'spca'\n",
       "      obsm:\t'X_pca', 'X_spca'\n",
       "      varm:\t'PCs', 'spca'\n",
       "      layers:\t'counts'\n",
       "      obsp:\t'wknn', 'wsnn'\n",
       "    ADT:\t75 x 228\n",
       "      var:\t'highly_variable', 'Split'\n",
       "      uns:\t'apca'\n",
       "      obsm:\t'X_apca'\n",
       "      varm:\t'apca'\n",
       "      layers:\t'counts'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 250 × 20729\n",
       "    var: 'highly_variable'\n",
       "    uns: 'pca', 'spca'\n",
       "    obsm: 'X_pca', 'X_spca'\n",
       "    varm: 'PCs', 'spca'\n",
       "    layers: 'counts'\n",
       "    obsp: 'wknn', 'wsnn'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[\"SCT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second function - Scenario 2. \n",
    "\n",
    "In this scenario, the MuonData object is split along the ADT axis based on the features, such that there is a 70% training set, 15% validation set, and 15% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_2_split(mudata_object, train_size = 0.7, val_size = 0.15, test_size = 0.15, seed = 42):\n",
    "    \"\"\"\n",
    "    Split the MuonData object into training, validation, and test sets. In this case, the split is \n",
    "    amongst the vars of the ADT aspect of the MuonData object.\n",
    "    \n",
    "    Parameters:\n",
    "    mudata_object (MuonData): MuonData object to split\n",
    "    train_size (float): Proportion of the dataset to include in the training set\n",
    "    val_size (float): Proportion of the dataset to include in the validation set\n",
    "    test_size (float): Proportion of the dataset to include in the test set\n",
    "    \n",
    "    Returns:\n",
    "    mudata_object (MuonData): MuonData object with the ADT vars annotated with the split\n",
    "    \"\"\"\n",
    "    # Get the indices of the ADT vars by enumerating over shape\n",
    "    adt_var_indices = [i for i in range(mudata_object[\"ADT\"].var.shape[0])]\n",
    "    \n",
    "    # Set the seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Split the indices based on the specified test/train/validation sizes\n",
    "    train_indices, test_indices = train_test_split(adt_var_indices, train_size=train_size)\n",
    "    val_indices, test_indices = train_test_split(test_indices, train_size=(val_size/(val_size + test_size)))\n",
    "    \n",
    "    \n",
    "    # Subset the mudata objects based on indices and return train/test/validation\n",
    "    mudata_object[\"ADT\"].var[\"Split\"] = \"None\"\n",
    "    mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
    "    mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
    "    mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n",
    "    \n",
    "    # Return the annodated split data\n",
    "    return mudata_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22124/3564735751.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:28: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
      "/tmp/ipykernel_22124/3564735751.py:29: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
      "/tmp/ipykernel_22124/3564735751.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n",
      "/tmp/ipykernel_22124/3564735751.py:30: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n"
     ]
    }
   ],
   "source": [
    "mdata_test = scenario_2_split(mdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define a function to extract the relevant arrays and features of the MuonData split objects. Three options will be used:\n",
    "\n",
    "- Option 1: Return AnnData objects of the Train, Validation and Test sets.\n",
    "- Option 2: Return the arrays of the Train, Validation and Test sets.\n",
    "- Option 3: Return torch tensors of the Train, Validation and Test sets.\n",
    "\n",
    "In both cases, the SCT and ADT subsets will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adt_split_returns(scenario = 1, mudata_train = None, mudata_val = None, mudata_test = None, return_type = \"AnnData\"):\n",
    "    # Scenario 1 conditions \n",
    "    if scenario == 1:\n",
    "        if return_type == \"AnnData\":\n",
    "            train_adt_adata = mudata_train[\"ADT\"].copy()\n",
    "            train_sct_adata = mudata_train[\"SCT\"].copy()\n",
    "            \n",
    "            val_adt_adata = mudata_val[\"ADT\"].copy()\n",
    "            val_sct_adata = mudata_val[\"SCT\"].copy()\n",
    "            \n",
    "            test_adt_adata = mudata_test[\"ADT\"].copy()\n",
    "            test_sct_adata = mudata_test[\"SCT\"].copy()\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "            \n",
    "        elif return_type == \"Numpy\":\n",
    "            train_adt_adata = mudata_train[\"ADT\"].X\n",
    "            train_sct_adata = mudata_train[\"SCT\"].X.todense()\n",
    "            \n",
    "            val_adt_adata = mudata_val[\"ADT\"].X\n",
    "            val_sct_adata = mudata_val[\"SCT\"].X.todense()\n",
    "            \n",
    "            test_adt_adata = mudata_test[\"ADT\"].X\n",
    "            test_sct_adata = mudata_test[\"SCT\"].X.todense()\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "            \n",
    "        elif return_type == \"Torch\":\n",
    "            train_adt_adata = torch.tensor(mudata_train[\"ADT\"].X)\n",
    "            train_sct_adata = torch.tensor(mudata_train[\"SCT\"].X.todense())\n",
    "            \n",
    "            val_adt_adata = torch.tensor(mudata_val[\"ADT\"].X)\n",
    "            val_sct_adata = torch.tensor(mudata_val[\"SCT\"].X.todense())\n",
    "            \n",
    "            test_adt_adata = torch.tensor(mudata_test[\"ADT\"].X)\n",
    "            test_sct_adata = torch.tensor(mudata_test[\"SCT\"].X.todense())\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "        else:\n",
    "            raise ValueError(\"Return type must be 'AnnData', 'Numpy', or 'Torch'\")\n",
    "        \n",
    "    # Scenario 2 conditions \n",
    "    elif scenario == 2:\n",
    "        if return_type == \"AnnData\":\n",
    "            train_sct_adata = mudata_train[\"SCT\"].copy()\n",
    "            val_sct_adata = mudata_train[\"SCT\"].copy()\n",
    "            test_sct_adata = mudata_train[\"SCT\"].copy()\n",
    "            \n",
    "            train_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Train\"].copy()\n",
    "            val_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Validation\"].copy()\n",
    "            test_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Test\"].copy()\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "            \n",
    "        elif return_type == \"Numpy\":\n",
    "            train_sct_adata = mudata_train[\"SCT\"].X.todense()\n",
    "            val_sct_adata = mudata_train[\"SCT\"].X.todense()\n",
    "            test_sct_adata = mudata_train[\"SCT\"].X.todense()\n",
    "            \n",
    "            train_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Train\"].X\n",
    "            val_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Validation\"].X\n",
    "            test_adt_adata = mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Test\"].X\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "            \n",
    "        elif return_type == \"Torch\":\n",
    "            train_sct_adata = torch.tensor(mudata_train[\"SCT\"].X.todense())\n",
    "            val_sct_adata = torch.tensor(mudata_train[\"SCT\"].X.todense())\n",
    "            test_sct_adata = torch.tensor(mudata_train[\"SCT\"].X.todense())\n",
    "            \n",
    "            train_adt_adata = torch.tensor(mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Train\"].X)\n",
    "            val_adt_adata = torch.tensor(mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Validation\"].X)\n",
    "            test_adt_adata = torch.tensor(mudata_train[\"ADT\"][:, mudata_train[\"ADT\"].var[\"Split\"] == \"Test\"].X)\n",
    "            \n",
    "            return train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Return type must be 'AnnData', 'Numpy', or 'Torch'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out all combinations of scenarios and options for returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/hmaan/miniconda3/envs/citeseq_env/lib/python3.9/site-packages/mudata/_core/mudata.py:489: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Subset the mudata object to manageable size to test the functions \n",
    "mdata_full = mdata.copy()\n",
    "mdata = mdata_full[0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_1_train, scenario_1_val, scenario_1_test = scenario_1_split(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 1, mudata_train = scenario_1_train, mudata_val = scenario_1_val, mudata_test = scenario_1_test, return_type = \"AnnData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 150 × 228\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 150 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n",
      "AnnData object with n_obs × n_vars = 25 × 228\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 25 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n",
      "AnnData object with n_obs × n_vars = 75 × 228\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 75 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n"
     ]
    }
   ],
   "source": [
    "# Print all the returns from previous \n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the same function but with numpy return type\n",
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 1, mudata_train = scenario_1_train, mudata_val = scenario_1_val, mudata_test = scenario_1_test, return_type = \"Numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28239354 0.91628971 1.28239354 ... 0.5368004  0.94738028 2.07283937]\n",
      " [1.52854319 0.57317092 0.82846665 ... 0.22949215 0.57317092 1.27525384]\n",
      " [0.50795782 0.33442464 0.65578345 ... 0.42495074 1.1372111  0.72223506]\n",
      " ...\n",
      " [1.61703022 0.64635629 1.13783482 ... 0.69789913 0.99923203 1.98225094]\n",
      " [0.48059421 0.95716045 0.90861493 ... 0.95716045 0.90861493 1.37669036]\n",
      " [0.51141641 0.7892629  1.05411149 ... 0.51141641 0.58844308 1.05411149]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.60106031 1.11845726 1.02440787 ... 0.67365535 1.07253782 1.35691226]\n",
      " [0.3748766  0.92268608 0.92268608 ... 0.794273   1.08884861 1.03647001]\n",
      " [0.99063706 0.87304651 2.32839216 ... 0.99063706 0.87304651 1.88354447]\n",
      " ...\n",
      " [2.95675998 0.58189022 1.46222571 ... 0.43992601 0.7061833  0.66644439]\n",
      " [1.41009148 0.79851371 1.2128301  ... 0.63990783 0.63990783 2.09050096]\n",
      " [0.28392384 0.83868676 0.68561653 ... 0.28392384 0.50480565 0.97140705]]\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.69314718 ... 0.         0.         0.        ]\n",
      " [0.         0.69314718 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.53669449 0.9950374  1.26898447 ... 0.82356961 1.18573775 0.75919253]\n",
      " [0.52315127 0.80522766 0.80522766 ... 0.52315127 1.20505548 1.07313799]\n",
      " [1.3193229  0.7926373  1.47837257 ... 0.63485988 0.75546485 2.23899454]\n",
      " ...\n",
      " [0.24667906 1.03620273 1.03620273 ... 0.68268723 0.75097886 0.87498595]\n",
      " [0.63886894 0.63886894 0.81185063 ... 0.42957364 2.34946608 1.2539462 ]\n",
      " [0.64307465 0.85589564 0.78986296 ... 0.78986296 0.71915974 1.38822655]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(150, 228)\n",
      "(150, 20729)\n",
      "(25, 228)\n",
      "(25, 20729)\n",
      "(75, 228)\n",
      "(75, 20729)\n"
     ]
    }
   ],
   "source": [
    "# Print all the returns from previous and their shapes \n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)\n",
    "\n",
    "print(train_adt_adata.shape)\n",
    "print(train_sct_adata.shape)\n",
    "print(val_adt_adata.shape)\n",
    "print(val_sct_adata.shape)\n",
    "print(test_adt_adata.shape)\n",
    "print(test_sct_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function with torch return type\n",
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 1, mudata_train = scenario_1_train, mudata_val = scenario_1_val, mudata_test = scenario_1_test, return_type = \"Torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2824, 0.9163, 1.2824,  ..., 0.5368, 0.9474, 2.0728],\n",
      "        [1.5285, 0.5732, 0.8285,  ..., 0.2295, 0.5732, 1.2753],\n",
      "        [0.5080, 0.3344, 0.6558,  ..., 0.4250, 1.1372, 0.7222],\n",
      "        ...,\n",
      "        [1.6170, 0.6464, 1.1378,  ..., 0.6979, 0.9992, 1.9823],\n",
      "        [0.4806, 0.9572, 0.9086,  ..., 0.9572, 0.9086, 1.3767],\n",
      "        [0.5114, 0.7893, 1.0541,  ..., 0.5114, 0.5884, 1.0541]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.6011, 1.1185, 1.0244,  ..., 0.6737, 1.0725, 1.3569],\n",
      "        [0.3749, 0.9227, 0.9227,  ..., 0.7943, 1.0888, 1.0365],\n",
      "        [0.9906, 0.8730, 2.3284,  ..., 0.9906, 0.8730, 1.8835],\n",
      "        ...,\n",
      "        [2.9568, 0.5819, 1.4622,  ..., 0.4399, 0.7062, 0.6664],\n",
      "        [1.4101, 0.7985, 1.2128,  ..., 0.6399, 0.6399, 2.0905],\n",
      "        [0.2839, 0.8387, 0.6856,  ..., 0.2839, 0.5048, 0.9714]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.6931,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.5367, 0.9950, 1.2690,  ..., 0.8236, 1.1857, 0.7592],\n",
      "        [0.5232, 0.8052, 0.8052,  ..., 0.5232, 1.2051, 1.0731],\n",
      "        [1.3193, 0.7926, 1.4784,  ..., 0.6349, 0.7555, 2.2390],\n",
      "        ...,\n",
      "        [0.2467, 1.0362, 1.0362,  ..., 0.6827, 0.7510, 0.8750],\n",
      "        [0.6389, 0.6389, 0.8119,  ..., 0.4296, 2.3495, 1.2539],\n",
      "        [0.6431, 0.8559, 0.7899,  ..., 0.7899, 0.7192, 1.3882]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "torch.Size([150, 228])\n",
      "torch.Size([150, 20729])\n",
      "torch.Size([25, 228])\n",
      "torch.Size([25, 20729])\n",
      "torch.Size([75, 228])\n",
      "torch.Size([75, 20729])\n"
     ]
    }
   ],
   "source": [
    "# Print all the returns from previous and their shapes \n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)\n",
    "\n",
    "print(train_adt_adata.shape)\n",
    "print(train_sct_adata.shape)\n",
    "print(val_adt_adata.shape)\n",
    "print(val_sct_adata.shape)\n",
    "print(test_adt_adata.shape)\n",
    "print(test_sct_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22124/3564735751.py:27: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  mudata_object[\"ADT\"].var[\"Split\"] = \"None\"\n",
      "/tmp/ipykernel_22124/3564735751.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:28: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][train_indices] = \"Train\"\n",
      "/tmp/ipykernel_22124/3564735751.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
      "/tmp/ipykernel_22124/3564735751.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
      "/tmp/ipykernel_22124/3564735751.py:29: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][val_indices] = \"Validation\"\n",
      "/tmp/ipykernel_22124/3564735751.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n",
      "/tmp/ipykernel_22124/3564735751.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n",
      "/tmp/ipykernel_22124/3564735751.py:30: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  mudata_object[\"ADT\"].var[\"Split\"][test_indices] = \"Test\"\n"
     ]
    }
   ],
   "source": [
    "# Do the same for scenario 2\n",
    "mdata_test = scenario_2_split(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 250 × 159\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 250 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n",
      "AnnData object with n_obs × n_vars = 250 × 34\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 250 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n",
      "AnnData object with n_obs × n_vars = 250 × 35\n",
      "    var: 'highly_variable', 'Split'\n",
      "    uns: 'apca'\n",
      "    obsm: 'X_apca'\n",
      "    varm: 'apca'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 250 × 20729\n",
      "    var: 'highly_variable'\n",
      "    uns: 'pca', 'spca'\n",
      "    obsm: 'X_pca', 'X_spca'\n",
      "    varm: 'PCs', 'spca'\n",
      "    layers: 'counts'\n",
      "    obsp: 'wknn', 'wsnn'\n"
     ]
    }
   ],
   "source": [
    "# Get the returns for scenario 2\n",
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 2, mudata_train = mdata_test, return_type = \"AnnData\")\n",
    "\n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.95916424 0.86914159 1.48523314 ... 0.55307644 1.04608444 1.72565693]\n",
      " [0.4322284  1.01422751 0.79594998 ... 0.66587988 0.85514588 1.37971736]\n",
      " [0.61381759 1.30390619 0.75610373 ... 0.6874892  0.75610373 1.04246048]\n",
      " ...\n",
      " [0.516672   0.79642125 1.23406963 ... 0.79642125 0.73347434 1.23406963]\n",
      " [0.34911635 0.81245902 1.17196872 ... 0.44281582 0.60738681 0.52848296]\n",
      " [0.71403457 0.78440454 1.07689159 ... 0.55643281 0.46721908 1.02484115]]\n",
      "[[0.         0.69314718 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.69314718 0.         ... 0.         0.         0.        ]]\n",
      "[[0.31429728 0.08830771 0.31429728 ... 0.08830771 1.16807008 0.37954604]\n",
      " [0.23928732 0.34040395 0.34040395 ... 0.         3.07019505 0.12678395]\n",
      " [0.13211989 0.13211989 0.353284   ... 0.13211989 2.27800534 0.13211989]\n",
      " ...\n",
      " [0.34065171 0.12688622 0.12688622 ... 0.         3.28989243 0.34065171]\n",
      " [0.34911635 0.         0.34911635 ... 0.         3.26074106 0.13038892]\n",
      " [0.63833527 0.26065161 0.55643281 ... 0.         2.51085599 0.36925965]]\n",
      "[[0.         0.69314718 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.69314718 0.         ... 0.         0.         0.        ]]\n",
      "[[0.82965976 0.37954604 3.8116121  ... 0.         0.08830771 0.78855481]\n",
      " [0.         0.73302822 5.77465368 ... 0.34040395 0.         0.73302822]\n",
      " [0.24880372 0.61381759 2.93369131 ... 0.353284   0.         0.61381759]\n",
      " ...\n",
      " [0.23947008 0.66629735 2.96522902 ... 0.59428054 0.23947008 0.516672  ]\n",
      " [0.24572096 0.44281582 2.78381179 ... 0.34911635 0.         0.60738681]\n",
      " [0.13879428 0.26065161 2.88888182 ... 0.36925965 0.13879428 0.46721908]]\n",
      "[[0.         0.69314718 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.69314718 0.         ... 0.         0.         0.        ]]\n",
      "(250, 159)\n",
      "(250, 20729)\n",
      "(250, 34)\n",
      "(250, 20729)\n",
      "(250, 35)\n",
      "(250, 20729)\n"
     ]
    }
   ],
   "source": [
    "# Get the returns for scenario 2 with numpy return type\n",
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 2, mudata_train = mdata_test, return_type = \"Numpy\")\n",
    "\n",
    "# Print all the returns from previous and their shapes \n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)\n",
    "\n",
    "print(train_adt_adata.shape)\n",
    "print(train_sct_adata.shape)\n",
    "print(val_adt_adata.shape)\n",
    "print(val_sct_adata.shape)\n",
    "print(test_adt_adata.shape)\n",
    "print(test_sct_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9592, 0.8691, 1.4852,  ..., 0.5531, 1.0461, 1.7257],\n",
      "        [0.4322, 1.0142, 0.7959,  ..., 0.6659, 0.8551, 1.3797],\n",
      "        [0.6138, 1.3039, 0.7561,  ..., 0.6875, 0.7561, 1.0425],\n",
      "        ...,\n",
      "        [0.5167, 0.7964, 1.2341,  ..., 0.7964, 0.7335, 1.2341],\n",
      "        [0.3491, 0.8125, 1.1720,  ..., 0.4428, 0.6074, 0.5285],\n",
      "        [0.7140, 0.7844, 1.0769,  ..., 0.5564, 0.4672, 1.0248]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.3143, 0.0883, 0.3143,  ..., 0.0883, 1.1681, 0.3795],\n",
      "        [0.2393, 0.3404, 0.3404,  ..., 0.0000, 3.0702, 0.1268],\n",
      "        [0.1321, 0.1321, 0.3533,  ..., 0.1321, 2.2780, 0.1321],\n",
      "        ...,\n",
      "        [0.3407, 0.1269, 0.1269,  ..., 0.0000, 3.2899, 0.3407],\n",
      "        [0.3491, 0.0000, 0.3491,  ..., 0.0000, 3.2607, 0.1304],\n",
      "        [0.6383, 0.2607, 0.5564,  ..., 0.0000, 2.5109, 0.3693]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.8297, 0.3795, 3.8116,  ..., 0.0000, 0.0883, 0.7886],\n",
      "        [0.0000, 0.7330, 5.7747,  ..., 0.3404, 0.0000, 0.7330],\n",
      "        [0.2488, 0.6138, 2.9337,  ..., 0.3533, 0.0000, 0.6138],\n",
      "        ...,\n",
      "        [0.2395, 0.6663, 2.9652,  ..., 0.5943, 0.2395, 0.5167],\n",
      "        [0.2457, 0.4428, 2.7838,  ..., 0.3491, 0.0000, 0.6074],\n",
      "        [0.1388, 0.2607, 2.8889,  ..., 0.3693, 0.1388, 0.4672]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6931, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([250, 159])\n",
      "torch.Size([250, 20729])\n",
      "torch.Size([250, 34])\n",
      "torch.Size([250, 20729])\n",
      "torch.Size([250, 35])\n",
      "torch.Size([250, 20729])\n"
     ]
    }
   ],
   "source": [
    "# Get the returns for scenario 2 with torch return type\n",
    "train_adt_adata, train_sct_adata, val_adt_adata, val_sct_adata, test_adt_adata, test_sct_adata = adt_split_returns(scenario = 2, mudata_train = mdata_test, return_type = \"Torch\")\n",
    "\n",
    "# Print all the returns from previous and their shapes \n",
    "print(train_adt_adata)\n",
    "print(train_sct_adata)\n",
    "print(val_adt_adata)\n",
    "print(val_sct_adata)\n",
    "print(test_adt_adata)\n",
    "print(test_sct_adata)\n",
    "\n",
    "print(train_adt_adata.shape)\n",
    "print(train_sct_adata.shape)\n",
    "print(val_adt_adata.shape)\n",
    "print(val_sct_adata.shape)\n",
    "print(test_adt_adata.shape)\n",
    "print(test_sct_adata.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 159])\n",
      "torch.Size([250, 34])\n",
      "torch.Size([250, 35])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_adt_adata.shape)\n",
    "print(val_adt_adata.shape)\n",
    "print(test_adt_adata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeseq_env",
   "language": "python",
   "name": "citeseq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
